<!doctype html>
<html>
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-M077D60Y90"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-M077D60Y90');
</script>

<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="author" content="山下陽介 (Yousuke Yamashita)  国立環境研究所 (National Institute for Environmental Studies, NIES)" />
<link rel="icon" type="image/vnd.microsoft.icon" href="/matplotlib/favicon.ico" />
<link rel="apple-touch-icon" type="image/png" href="/matplotlib/images/apple-touch-icon-180x180.png" />
<link rel="icon" type="image/png" href="/matplotlib/images/icon-192x192.png" />
<link rel="icon" type="image/x-icon" href="/matplotlib/favicon.ico" />
<!-- Mobile Internet Explorer allows us to activate ClearType technology for smoothing fonts for easy reading -->
<meta http-equiv="cleartype" content="on" />
<!-- Specify whether or not telephone numbers in the HTML content should appear as hypertext links -->
<meta name="format-detection" content="telephone=no" />
<!-- Changes the logical window size used when displaying a page mobile browsers -->
<meta name = "viewport" content = "width = device-width, initial-scale=1, user-scalable=yes" />

<meta name="robots" content="all" />
<meta name="http-equiv" content="X-Robots-Tag : all" />
<meta name="googlebot" content="all" />
<meta name="description" content="" />
<meta name="keywords" content="" />
<link href="design.css" rel="stylesheet" type="text/css" />
<title>気象データ解析のためのmatplotlibの使い方：気象データ処理</title>
<meta property="og:title" content="気象データ解析のためのmatplotlibの使い方：気象データ処理" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://yyousuke.github.io/matplotlib/metdata.html" />
<meta property="og:image" content="https://yyousuke.github.io/matplotlib/images/logo.png" />
<meta property="og:site_name" content="気象データ解析のためのmatplotlibの使い方" />
<meta property="og:description" content="pythonによる気象データ処理のTIPSを載せています" />
<meta property="fb:app_id" content="902607720378666" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@yyousuke1109" />
<meta name="twitter:player" content="@yyousuke1109" />
</head>

<body>

<div id="nesting">
<a href="/">ホーム</a> &gt; <a href="index.html">matplotlibの使い方</a> &gt; 気象データ処理のTIPS
</div>
<article>
<h1 id="top">matplotlib：気象データ処理のTIPS</h1>
<br />
<div id="text2">
<p>作成者：山下陽介（国立環境研究所）</p>
</div>
<hr />
<br />

<!-- 目次 -->
<h2 id="contents">目次</h2>
<div class="contents">
  <!--  CSVファイル -->
  <ul class="list1"><li><a href="#csv_1">CSVファイル</a>
    <ul class="list2">
      <li><a href="#csv_1_1">CSVファイルの形式</a></li>
      <li><a href="#csv_1_2">CSVファイルの読み込み</a></li>
      <li><a href="#csv_1_3">CSVファイルの時刻処理</a></li>
      <li><a href="#csv_1_4">CSVファイルの行処理</a></li>
      <li><a href="#csv_1_5">CSVファイルの時刻がparse_dates未対応の場合</a></li>
      <li><a href="#csv_1_6">CSVファイルの列処理</a></li>
      <li><a href="#csv_1_7">CSVファイルとして書き出す</a></li>
      <li><a href="#csv_1_8">CSVデータの文字列を数値に変換する</a></li>
      <li><a href="#csv_1_9">CSVファイル読み込み時のエラー</a></li>
      <li><a href="#csv_1_10">圧縮されたCSVファイルの読み込み</a></li>
      <li><a href="#csv_1_11">CSVファイルを圧縮して書き出し</a></li>
     </ul>
  </li></ul>
  <!--  TSVファイル -->
  <ul class="list1"><li><a href="#tsv_1">TSVファイル</a>
    <ul class="list2">
      <li><a href="#tsv_1_1">TSVファイルの形式</a></li>
      <li><a href="#tsv_1_2">TSVファイルの読み込み</a></li>
      <li><a href="#tsv_1_3">TSVファイルとして書き出す</a></li>
      <li><a href="#tsv_1_4">LTSVファイル</a></li>
     </ul>
  </li></ul>
  <!--  SSVファイル -->
  <ul class="list1"><li><a href="#ssv_1">SSVファイル</a>
    <ul class="list2">
      <li><a href="#ssv_1_1">SSVファイルの形式</a></li>
      <li><a href="#ssv_1_2">SSVファイルの読み込み</a></li>
      <li><a href="#ssv_1_3">SSVファイルとして書き出す</a></li>
     </ul>
  </li></ul>
  <!--  JSONファイル -->
  <ul class="list1"><li><a href="#json_1">JSONファイル</a>
    <ul class="list2">
      <li><a href="#json_1_1">JSONファイルの形式</a></li>
      <li><a href="#json_1_2">JSONファイルの読み込み</a></li>
      <li><a href="#json_1_3">JSONファイルの書き出し</a></li>
     </ul>
  </li></ul>
  <!--  バイナリファイル -->
  <ul class="list1"><li><a href="#bin_1">バイナリファイル</a>
    <ul class="list2">
      <li><a href="#bin_1_1">バイナリファイルの形式</a></li>
      <li><a href="#bin_1_2">バイナリファイルのエンディアン</a></li>
      <li><a href="#bin_1_3">バイナリファイルの読み込み</a></li>
      <li><a href="#bin_1_4">バイナリファイルの書き出し</a></li>
    </ul>
  </li></ul>
  <!--  Numpy独自のバイナリファイル -->
  <ul class="list1"><li><a href="#bin_2">Numpy独自のバイナリファイル</a>
    <ul class="list2">
      <li><a href="#bin_2_1">Numpy独自のバイナリファイルの形式</a></li>
      <li><a href="#bin_2_2">Numpy独自のバイナリファイルの読み書き</a></li>
    </ul>
  </li></ul>  
  <!--  NetCDFファイル -->
  <ul class="list1"><li><a href="#nc_1">NetCDFファイル</a>
    <ul class="list2">
      <li><a href="#nc_1_1">NetCDFファイルの形式</a></li>
      <li><a href="#nc_1_2">NetCDFのモジュール</a></li>
      <li><a href="#nc_1_3">NetCDFファイルの読み込み</a></li>
      <li><a href="#nc_1_4">NetCDFファイル情報の取得</a></li>
      <li><a href="#nc_1_5">データにスケールファクターとオフセットがある場合</a></li>
      <li><a href="#nc_1_6">変数がグループ化されている場合</a></li>
    </ul>
  </li></ul>
  <!--  GRIB2ファイル -->
  <ul class="list1"><li><a href="#grib2_1">GRIB2ファイル</a>
    <ul class="list2">
      <li><a href="#grib2_1_1">GRIB2ファイルの形式</a></li>
      <li><a href="#grib2_1_2">GRIB2ファイルの読み込み</a></li>
      <li><a href="#grib2_1_3">pygribを使ったGRIB2ファイルの読み込み</a></li>
      <li><a href="#grib2_1_4">wgrib2による単純バイナリファイルへの変換</a></li>     
    </ul>
  </li></ul>
  <!--  GRIB1ファイル -->
  <ul class="list1"><li><a href="#grib1_1">GRIB1ファイル</a>
    <ul class="list2">
      <li><a href="#grib1_1_1">GRIB1ファイルの形式</a></li>
      <li><a href="#grib1_1_2">GRIB1ファイルの読み込み</a></li>
    </ul>
  </li></ul>
  <!--  HDF5ファイル -->
  <ul class="list1"><li><a href="#hdf5_1">HDF5ファイル</a>
    <ul class="list2">
      <li><a href="#hdf5_1_1">HDF5ファイルの形式</a></li>
      <li><a href="#hdf5_1_2">HDF5ファイルの読み込み</a></li>
    </ul>
  </li></ul>
  <!--  GTOOL3フファイル -->
  <ul class="list1"><li><a href="#gtool3_1">GTOOL3ファイル</a>
    <ul class="list2">
      <li><a href="#gtool3_1_1">GTOOL3ファイルの形式</a></li>
      <li><a href="#gtool3_1_2">GTOOL3ファイルの読み込み</a></li>
    </ul>
  </li></ul>
  <!--  画像ファイル -->
  <ul class="list1"><li><a href="#img_1">画像ファイル</a>
    <ul class="list2">
      <li><a href="#img_1_1">画像ファイルの読み込み（Pillow）</a></li>
      <li><a href="#img_1_2">画像ファイルの書き出し（Pillow）</a></li>
      <li><a href="#img_1_3">読み込んだ画像の処理（Pillow）</a></li>
    </ul>
  </li></ul>
</div>

<small><a href="#top">[top]</a></small> <br />
<br />
<hr width="105%" />
<br />

<!-- ここから本文 -->
<!-- CSVファイル -->
<h3><div class="headline1" id="csv_1">CSVファイル</div></h3>
<h4><div class="headline2" id="csv_1_1">CSVファイルの形式</div></h4>
	<div class="text1">
		CSV（Comma-Separated Values）は、カンマ区切りのテキストデータ
		<pre>時刻,項目1,項目2,項目3<br />時刻1,データ1-1,データ1-2,データ1-3<br />時刻2,データ2-1,データ2-2,データ2-3<br />...</pre>
		＊<a href="#csv_1_4">ヘッダがない場合</a>を扱うことも可能
	</div>

<h4><div class="headline2" id="csv_1_2">CSVファイルの読み込み</div></h4>
	<div class="text1">
		pandasのread_csvを用いる方法
		<pre>import pandas as pd<br />df = pd.read_csv("ファイル名")</pre>
		＊読み込み時にUnicodeDecodeErrorが出る場合は、<a href="#csv_1_9">CSVファイル読み込み時のエラー</a>参照
	</div>

<h4><div class="headline2" id="csv_1_3">CSVファイルの時刻処理</div></h4>
	<div class="text1">
		<ul class="list1">
			<li>例：1列目が時刻データの場合<pre>import pandas as pd<br />df = pd.read_csv("ファイル名", parse_dates=[0], index_col=[0])</pre>
				parse_datesには時刻データとして処理する列、index_colにはindexとして扱う列を指定<br />
				時刻データはdf.indexになる
			</li><br />
			<li>例：1列目が年、2列目が月のように複数列に時刻データが入っている場合
				<pre>df = pd.read_csv("ファイル名", parse_dates=[[0, 1]], index_col=[0])</pre>
				時刻データはdf.indexになり、年、月単独のデータは参照できない
			</li><br />
			<li>例：1列目が月、2列目が年のように並びが逆の場合
				<pre>df = pd.read_csv("ファイル名", parse_dates=[[1, 0]], index_col=[0])</pre>
			</li>
			<li>例：読み込んだ年、月の時刻データも残したい場合
				<pre>df = pd.read_csv("ファイル名", parse_dates=[[0, 1]], index_col=[0], keep_date_col=True)</pre>
				時刻データはdf.index、年、月のデータはdf.year、df.monthなどになる（yearやmonthなどは、ヘッダに記述された名前になる）
			</li>
		</ul>
	</div>

<h4><div class="headline2" id="csv_1_4">CSVファイルの行処理</div></h4>
	<div class="text1">
		<ul class="list1">
			<li>例：1行目にヘッダがなく、1行目からデータが入っている場合
				<pre>import pandas as pd<br />df = pd.read_csv("ファイル名", header=None)</pre>
			</li>
			<li>例：ヘッダがない場合に、読み込み時に任意のヘッダを付ける<br />
				<pre>df = pd.read_csv("ファイル名", header=None, names=[名前1, 名前2, , ,名前n])</pre>namesに与えるリストの要素数は、データの列数に合わせる
			</li><br />
			<li>例：1〜3行目にデータ以外のもの（データの説明など）が入っており、4行目がヘッダの場合
				<pre>df = pd.read_csv("ファイル名", skiprows=[0, 1, 2])</pre>
			</li>
			<li>例：1〜3行目にデータ以外のもの（データの説明など）が入っており、4行目からデータが入っている場合
				<pre>df = pd.read_csv("ファイル名", skiprows=[0, 1, 2], header=None)</pre>
			</li>
			<li>例：最初から50行を読み飛ばしたい場合
				<pre>df = pd.read_csv("ファイル名", skiprows=50)</pre>
			</li>
		</ul>
	</div>

<h4><div class="headline2" id="csv_1_5">CSVファイルの時刻がparse_dates未対応の場合</div></h4>
	<div class="text1">
		日付データへの変換処理をdate_parserに関数で指定
		<pre>import pandas as pd<br />df = pd.read_csv("ファイル名", parse_dates=[0], index_col=[0], date_parser=parse_dates)</pre>
		parse_datesが関数名
		<ul class="list1">
			<li>例：時刻形式がGrADSで扱われる「00Z03FEB2020」のような形式の場合
				<pre>from datetime import datetime<br />def parse_dates(x):<br />&nbsp; &nbsp; return datetime.strptime(x, "%HZ%d%b%Y")<br /><br />df = pd.read_csv("ファイル名", parse_dates=[0], index_col=[0], date_parser=parse_dates)</pre>
				時刻表記の書式については<a href="forms.html#time">時刻表記に用いられる書式指定子一覧</a>参照</li><br /><li>例：時刻形式が「2020/02/03 00:00」のような形式の場合
			<pre>from datetime import datetime<br />def parse_dates(x):&nbsp; &nbsp; return datetime.strptime(x, "%Y/%m/%d %H:%M")<br /><br />df = pd.read_csv("ファイル名", parse_dates=[0], index_col=[0], date_parser=parse_dates)</pre>
			</li>
		</ul>
	</div>

<h4><div class="headline2" id="csv_1_6">CSVファイルの列処理</div></h4>
	<div class="text1">
		<ul class="list1">
			<li>例：読み込む列を指定する
				<pre>import pandas as pd<br />df = pd.read_csv("ファイル名", usecols=[0, 3])</pre>
				1列目と4列目を読み込む
			</li><br />
			<li>例：経度データを−180〜180度ではなく0〜360度に
				<pre>df = pd.read_csv("ファイル名", オプション)<br />lons = np.array([l + 360. if l &lt; 0 else l for l in df.loc[:, "longitude"]])</pre>
				経度ラベルがlongitudeの場合<br />
				経度データを読み、0度より小さい場合に360度を足す<br />
				リスト内包表記でリストにしたものを、Numpyのndarrayに変換して格納する（np.arrayをpd.SeriesにするとSeriesになる）
			</li>
		</ul>
	</div>

<h4><div class="headline2" id="csv_1_7">CSVファイルとして書き出す</div></h4>
	<div class="text1">
		pandasのDataFrameを使う場合
		<ul class="list1">
			<li>DataFrameを書き出す
				<pre>import pandas as pd<br />pd.DataFrame(d).to_csv("ファイル名")</pre>
				dはlistやnumpyのndarrayなど</li><br />
			<li>indexを無効にしてから書き出す
				<pre>pd.DataFrame(d).to_csv("ファイル名", index=False)</pre>
				1列目に番号などが入らないファイルができる</li><br />
			<li>ヘッダを付けない
				<pre>pd.DataFrame(d).to_csv("ファイル名", header=False)</pre>
				1行目にヘッダ行が入らないファイルができる</li><br />
			<li>indexもヘッダも付けないこともできる
				<pre>pd.DataFrame(d).to_csv("ファイル名", header=False, index=False)</pre>
				データのみのファイルができる</li><br />
			<li>カンマ区切りではなくタブ区切りで出力する（<a href="#tsv_1">TSVファイル</a>にする）
				<pre>pd.DataFrame(d).to_csv("ファイル名", sep='\t')</pre>
				sepで区切り文字をタブにする</li><br />
			<li>複数のndarrayからDataFrameを作成して書き出す
				<pre>
				df = pd.DataFrame(<br />&nbsp; &nbsp; {<br />&nbsp; &nbsp; &nbsp; &nbsp; 'index': np.array(index),<br />&nbsp; &nbsp; &nbsp; &nbsp; 'mean': np.array(dmean),<br />&nbsp; &nbsp; &nbsp; &nbsp; 'std': np.array(dstd)<br />&nbsp; &nbsp; },<br />&nbsp; &nbsp; dtype='float')<br />df.to_csv("ファイル名")</pre>
				indexは時刻データ、meanは平均値、stdは標準偏差の場合で、ヘッダ行ありで書き出す<br />
				書き出す際にndarrayに変換しているので、元のindex、dmean、dstdはリスト、タプル、1次元の配列、pandasのSeriesなどに対応（サイズが異なるとエラー）</li><br />
			<li>CSVをbz2圧縮して書き出す
				<pre>import bz2<br />df.to_csv("圧縮後のファイル.bz2", compression='bz2')</pre>
			</li><br />
			<li>CSVファイルの末尾に行を追記する<pre>df.to_csv("ファイル名")  # 新しいファイルを作成<br />df2.to_csv("ファイル名", mode='a', header=False)  # 追記</pre>
				mode='a'が追記を表す（デフォルトはmode='w'で、存在しない場合は新規作成、存在する場合は上書き）<br />
				追記する場合、CSVファイルの途中にヘッダが入らないようにheader=Falseとする
			</li><br />
		</ul>
	</div>

<h4><div class="headline2" id="csv_1_8">CSVデータの文字列を数値に変換する</div></h4>
	<div class="text1">
		文字列のまま一度書き出し、再読み込みを行うと数値データに変換される
		<ul class="list1">
			<li>ファイルを利用する方法
				<pre>df.to_csv("tmp.csv", index=False)<br />df = pd.read_csv("tmp.csv")</pre>
				dfはpandasのDataFrame
			</li><br />
			<li>StringIOを利用する方法
				<pre>from io import StringIO<br />csv = df.to_csv(index=False)<br />df = pd.read_csv(StringIO(csv))</pre>
				行の読み飛ばしオプションにも対応（<a href="#csv_1_4">CSVファイルの行処理</a>参照）
			</li><br />
		</ul>
	</div>

<h4><div class="headline2" id="csv_1_9">CSVファイル読み込み時のエラー</div></h4>
	<div class="text1">
		読み込み時にUnicodeDecodeErrorが出る場合（UTF-8でない場合には、文字化けではなくエラーとなる）
		<pre>df = pd.read_csv("ファイル名", encoding='shift_jis')</pre>
		＊WindowsのShift JISで読み込む
	</div>

<h4><div class="headline2" id="csv_1_10">圧縮されたCSVファイルの読み込み</div></h4>
	<div class="text1">
		pd.read_csvのcompressionオプションは、デフォルトで'infer'なので、ファイルの拡張子を見て圧縮ファイルかどうか判断してくれる
		<pre>df = pd.read_csv("ファイル名")</pre>
		具体的に圧縮形式を指定する場合、 pd.read_csvにcompressionオプションを付ける。
		<pre>df = pd.read_csv("ファイル名", compression="bz2")</pre>
		＊bz2で圧縮されたCSVファイルを読み込む
	</div>

<h4><div class="headline2" id="csv_1_11">CSVファイルを圧縮して書き出し</div></h4>
	<div class="text1">
		pandasのDataFrameの書き出しの際にcompressionオプションを付ける
		<pre>df.to_csv("ファイル名.gz", compression='gzip')</pre>
		＊gzipで圧縮したCSVファイルを書き出す
	</div>


<!-- TSVファイル -->
<h3><div class="headline1" id="tsv_1">TSVファイル</div></h3>
<h4><div class="headline2" id="tsv_1_1">TSVファイルの形式</div></h4>
	<div class="text1">
		TSV（Tab-Separated Values）は、タブ区切りのテキストデータ
		<pre>時刻&lt;tab&gt;項目&lt;tab&gt;項目2&lt;tab&gt;項目3<br />時刻1&lt;tab&gt;データ1-1&lt;tab&gt;データ1-2&lt;tab&gt;データ1-3<br />時刻2&lt;tab&gt;データ2-1&lt;tab&gt;データ2-2&lt;tab&gt;データ2-3<br />...</pre>
		＊&lt;tab&gt;は制御文字のHT（Horizontal Tabulation：水平タブ）を表す
	</div>

<h4><div class="headline2" id="tsv_1_2">TSVファイルの読み込み</div></h4>
	<div class="text1">
		pandasのread_csvにsepオプションを与える
		<ul class="list1">
			<li>ヘッダ有りの場合
				<pre>df = pd.read_csv("ファイル名", sep='\t')</pre>
				CSVファイルのセパレータがタブであることを指定<br />
				ヘッダが列の名前になる</li><br />
			<li>ヘッダ無しの場合
				<pre>df = pd.read_csv("ファイル名", sep='\t', header=None)</pre>
			</li>
			<li>ヘッダ無しのファイルを読み込み列の名前を付ける場合
				<pre>df = pd.read_csv("ファイル名", sep='\t', header=None, names=('列1の名前', '列2の名前'))</pre>
			</li>
		</ul>
		＊読み込み時にUnicodeDecodeErrorが出る場合は、<a href="#csv_1_9">CSVファイル読み込み時のエラー</a>参照
	</div>

<h4><div class="headline2" id="tsv_1_3">TSVファイルとして書き出す</div></h4>
	<div class="text1">
		pandasのDataFrameを使う場合
		<ul class="list1">
			<li>DataFrameを書き出す
				<pre>pd.DataFrame(d).to_csv("ファイル名", sep='\t')</pre>
				dはlistやnumpyのndarrayなど</li><br />
			<li>indexを無効にしてから書き出す
				<pre>pd.DataFrame(d).to_csv("ファイル名", sep='\t', index=False)</pre>
				1列目に番号などが入らないファイルができる</li><br />
			<li>ヘッダを付けない
				<pre>pd.DataFrame(d).to_csv("ファイル名", sep='\t', header=False)</pre>
				1行目にヘッダ行が入らないファイルができる</li>
		</ul>
	</div>

<h4><div class="headline2" id="tsv_1_4">LTSVファイル</div></h4>
	<div class="text1">
		TSVファイルの中には、Labeled Tab-separated Values（LTSV）形式のものがある。各列にラベルを付けることで、データが欠損になった場合やデータが追加になった場合にも柔軟に対応できる。
		<ul class="list1">
			<li>LTSV形式のファイルの形式
				<pre>time:時刻1&lt;tab&gt; lat:緯度1&lt;tab&gt; lon:経度1&lt;tab&gt; t:気温1&lt;tab&gt; p:気圧1<br />time:時刻2&lt;tab&gt; lat:緯度2&lt;tab&gt; lon:経度2&lt;tab&gt; t:気温2&lt;tab&gt; p:気圧2<br />...</pre>
			</li><br />
			<li>LTSV形式のファイルを読み込む
				<pre>from collections import OrderedDict<br />with open(path_to_file) as f:<br />&nbsp; &nbsp; df = pd.DataFrame([<br />&nbsp; &nbsp; &nbsp; &nbsp; OrderedDict(<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cell.split(':', 1) for cell in line.rstrip('\r\n').split('\t'))<br />&nbsp; &nbsp; &nbsp; &nbsp; for line in f<br />&nbsp; &nbsp; ])</pre>
			</li><br />
		</ul>
	</div>


<!-- SSVファイル -->
<h3><div class="headline1" id="ssv_1">SSVファイル</div></h3>
<h4><div class="headline2" id="ssv_1_1">SSVファイルの形式</div></h4>
	<div class="text1">
		SSV（Space-Separated Values）は、スペース区切りのテキストデータ
		<pre>時刻 &nbsp;項目 &nbsp;項目2 &nbsp;項目3<br />時刻1 &nbsp;データ1-1 &nbsp;データ1-2 &nbsp;データ1-3<br />時刻2 &nbsp;データ2-1 &nbsp;データ2-2 &nbsp;データ2-3<br />...</pre>
	</div>

<h4><div class="headline2" id="ssv_1_2">SSVファイルの読み込み</div></h4>
	<div class="text1">
		pandasのread_csvにsepオプションを与える
		<ul class="list1">
			<li>ヘッダ有りの場合
				<pre>df = pd.read_csv("ファイル名", sep='\s+')</pre>
				CSVファイルのセパレータがスペース（連続する任意の文字数のスペース）であることを指定する<br />
				ヘッダが列の名前になる</li><br />
			<li>ヘッダ無しの場合
				<pre>df = pd.read_csv("ファイル名", sep='\s+', header=None)</pre>
			</li>
			<li>ヘッダ無しのファイルを読み込み列の名前を付ける場合
				<pre>df = pd.read_csv("ファイル名", sep='\s+', header=None, names=('列1の名前', '列2の名前'))</pre>
			</li><br />
			<li>固定長のSSVファイルの場合
				<pre>df = pd.read_fwf("ファイル名")</pre>
				個々のレコードが記述されている列が、ファイル全体で不変の場合
			</li><br />
			<li>ヘッダ無しの場合
				<pre>df = pd.read_fwf("ファイル名", header=None)</pre>
			</li>
		</ul>
		＊読み込み時にUnicodeDecodeErrorが出る場合は、<a href="#csv_1_9">CSVファイル読み込み時のエラー</a>参照
	</div>

<h4><div class="headline2" id="ssv_1_3">SSVファイルとして書き出す</div></h4>
	<div class="text1">
		pandasのDataFrameを使う場合
		<ul class="list1">
			<li>DataFrameを書き出す
				<pre>pd.DataFrame(d).to_csv("ファイル名", sep=' ')</pre>
				dはlistやnumpyのndarrayなど</li><br />
			<li>indexを無効にしてから書き出す
				<pre>pd.DataFrame(d).to_csv("ファイル名", sep=' ', index=False)</pre>
				1列目に番号などが入らないファイルができる</li><br />
			<li>ヘッダを付けない
				<pre>pd.DataFrame(d).to_csv("ファイル名", sep=' ', header=False)</pre>
				1行目にヘッダ行が入らないファイルができる</li>
		</ul>
	</div>



<!-- JSONファイル -->
<h3><div class="headline1" id="json_1">JSONファイル</div></h3>
<h4><div class="headline2" id="json_1_1">JSONファイルの形式</div></h4>
	<div class="text1">
		データの名前（キー）とデータの組み合わせを決められたフォーマットで記述し、階層構造を持たせたテキストデータ
		<pre>{"時刻1":{<br />&nbsp; &nbsp; {"キー1":"データ1"},<br />&nbsp; &nbsp; {"キー2":"データ2"},<br />&nbsp; &nbsp; {"キー3":["データ3-1","データ3-2","データ3-3"]},<br />&nbsp; &nbsp; ...},<br />"時刻2":{<br />&nbsp; &nbsp; {"キー1":"データ1"},<br />&nbsp; &nbsp; {"キー2":"データ2"},<br />&nbsp; &nbsp; {"キー3":["データ3-1","データ3-2","データ3-3"]},<br />&nbsp; &nbsp; ...},<br />...<br />}</pre>
		＊時刻毎に複数のデータが入っている場合
	</div>

<h4><div class="headline2" id="json_1_2">JSONファイルの読み込み</div></h4>
	<div class="text1">
		<ul class="list1">
			<li>jsonモジュールを使う
				<pre>import pandas as pd<br />import json<br />with open('ファイル名', 'rt') as fin:<br />&nbsp; &nbsp; data = fin.read()<br />df = pd.DataFrame(json.loads(data))</pre>
				データの名前を指定する場合
				<pre>obj = json.loads(data)<br />df = pd.DataFrame(obj['データ名'])</pre>
			</li><br />
			<li>Pandasで直接読み込み
				<pre>import pandas as pd<br />df = pd.read_json('ファイル名')</pre>
			</li><br />
		</ul>
	</div>

<h4><div class="headline2" id="json_1_3">JSONファイルの書き出し</div></h4>
	<div class="text1">
		jsonモジュールを使う
		<pre>import json<br />d = ...<br />with open('ファイル名', 'w') as fout:<br />&nbsp; &nbsp; json.dump(d, fout)<br />df = pd.DataFrame(json.loads(data))</pre>
		データの形式については、<a href="#json_1_1">JSONファイルの形式</a>参照
	</div>


<!--  バイナリファイル -->
<h3><div class="headline1" id="bin_1">バイナリファイル</div></h3>
<h4><div class="headline2" id="bin_1_1">バイナリファイルの形式</div></h4>
<div class="text1">
ここでは、GrADS等で用いられる下記の形式の単純なバイナリファイルについて記載している。<a href="#bin_2">NumPy独自のバイナリ（npy、npz）</a>とは異なる。<br />
4バイト浮動小数点数（単精度）のデータや8バイト浮動小数点数（倍精度）のデータを改行コード無しで並べた単純バイナリ形式<br />
<ul class="list1">
<li>例：単精度で経度、緯度方向とも10度の等間隔データの場合
<pre>
t=0： | 0E, 90N | 10E, 90N | ... | 350E, 90N |
t=0： | 0E, 80N | 10E, 80N | ... | 350E, 80N |
...
t=1： | 0E, 90S | 10E, 80N | ... | 350E, 80N |
t=1： | 0E, 90N | 10E, 90N | ... | 350E, 90N |
t=1： | 0E, 80N | 10E, 80N | ... | 350E, 80N |
...
t=1： | 0E, 90S | 10E, 80N | ... | 350E, 80N |
</pre>
| |で囲まれた部分がデータを表していて、1つのサイズが4バイト<br />
</li>
</ul>
</div>

<h4><div class="headline2" id="bin_1_2">バイナリファイルのエンディアン</div></h4>
<div class="text1">
エンディアン：2バイト以上のデータを保存する場合の保存順序の規則<br />
ビックエンディアン（Big Endian）とリトルエンディアン（Little endian）の２種類
<ul class="list1">
<li>例：4バイトの場合
<pre>
データ：AABBCCDD

ビックエンディアン：AABBCCDD（上位から保存）
リトルエンディアン：DDCCBBAA（下位から保存）
</pre>
</li>
</ul>
</div>


<h4><div class="headline2" id="bin_1_3">バイナリファイルの読み込み</div></h4>
<div class="text1">
<ul class="list1">
<li>Numpyを使った方法（先頭からdatasize分だけ読み込み）
<pre>
import numpy as np

endian = 'big'
idim = 288 # 経度方向のサイズ（整数）
jdim = 145 # 緯度方向のサイズ（整数）
num_rec = 3 # データの個数（整数）
datasize = idim * jdim * num_rec # 読み込むデータサイズ（個数）
if endian == 'big':
&nbsp; &nbsp; din = np.fromfile('読み込むファイル名', dtype='&gt;f4', count=datasize)
else:
&nbsp; &nbsp; din = np.fromfile('読み込むファイル名', dtype='&lt;f4', count=datasize)
d = din.reshape(num_rec, jdim, idim)
</pre>
ビックエンディアンの単精度（4バイト）浮動小数点数の場合がdtype='&gt;f4'の書式に対応<br />
リトルエンディアンの場合にはdtype='&lt;f4'となる<br />
書式の一覧は<a href="numpy.html#dtype_2">Numpyバイナリデータ読み書きの書式一覧</a>参照
</li><br />
<li>arrayを使った方法（指定した時刻データを切り出す）<br />
np.fromfileではメモリサイズ不足の場合など
<pre>
import array
import sys

idim = 288 # 経度方向のサイズ（整数）
jdim = 145 # 緯度方向のサイズ（整数）
tsta = 5 # 開始データ番号（整数、データの先頭番号は１）
tend = 7 # 終了データ番号（整数、データの先頭番号は１）
datasize = idim * jdim # 水平方向のデータサイズ（個数）
with open('読み込むファイル名', 'rb') as fin:
&nbsp; &nbsp; fin.seek(4 * datasize * (tsta - 1), 0) # 開始データの前まで読み飛ばす（単位：byte）
&nbsp; &nbsp; buf = array.array('f') # 4バイト浮動小数点数
&nbsp; &nbsp; buf.fromfile(fin, datasize * (tend - tsta + 1)) # データの読み込み
&nbsp; &nbsp; if sys.byteorder == 'little':
&nbsp; &nbsp; &nbsp; &nbsp; buf.byteswap()
# bufからlistに変換し、x-, y-の配列に
d = np.array(buf.tolist()).reshape(jdim, idim)
</pre>
4バイト浮動小数点数の場合のarray書式（'f'）<br />
sys.byteorderを使い、ビックエンディアンとリトルエンディアンを判定（システムがリトルエンディアンの場合にビックエンディアンとして読み込むようにしている）<br />
ここではデータの先頭番号が１としているが、先頭番号を0としたい場合には、tsta - 1をtstaに、tend - tsta + 1をtend - tstaに変える<br />
8バイト浮動小数点数の場合、array書式（'d'）となり、fin.seekで読み飛ばすサイズは8*datasize*レコード数（byte）、となる
</li>
</ul>
</div>

<h4><div class="headline2" id="bin_1_4">バイナリファイルの書き出し</div></h4>
<div class="text1">
<ul class="list1">
<li>Numpyを使った方法（ndarrayのメソッドを使って書き出す）
<pre>
np.array(d).tofile("ファイル名")
</pre>
dはlistやnumpyのndarray、pandasのDataFrameなど<br />
書き出されるデータのエンディアンはマシン依存</li><br />
<li>データの型を指定する場合
<pre>
np.array(d).tofile("ファイル名", dtype=np.float32)
</pre>
単精度（4バイト）浮動小数点型で書き出す場合</li><br />
<li>データをbig endianで書き出す場合
<pre>
np.array(d).astype('&gt;f4').tofile("ファイル名")
</pre></li>
<li>データをlittle endianで書き出す場合
<pre>
np.array(d).astype('&lt;f4').tofile("ファイル名")
</pre></li>
<li>データを倍精度（8バイト）浮動小数点型のlittle endianで書き出す場合
<pre>
np.array(d).astype('&lt;f8').tofile("ファイル名")
</pre>
書式の一覧は<a href="numpy.html#dtype_2">Numpyバイナリデータ読み書きの書式一覧</a>参照</li>
</ul>
</div>


<!--  Numpy独自のバイナリファイル -->
<h3><div class="headline1" id="bin_2">Numpy独自のバイナリファイル</div></h3>
<h4><div class="headline2" id="bin_2_1">Numpy独自のバイナリファイルの形式</div></h4>
<div class="text1">
Numpyでは、内部で使われている配列ndarrayをNumpy独自のバイナリファイル（npy、npz）として保存できる。配列のデータ型や形状を保持でき、npyでは1つの配列、npzでは複数の配列を保存できる。このバイナリ形式はNumpy独自であり機種依存性もあるため、基本的には同じマシンでNumpyを利用して読み書きを行う。
</div>

<h4><div class="headline2" id="bin_2_2">Numpy独自のバイナリファイルの読み書き</div></h4>
<div class="text1">
モジュールをインポートする
<pre>import numpy as np</pre><br />
<ul class="list1">
<li>Numpyを使って読み込む（npy、npz共通）
<pre>d = np.load('ファイルへのパス')</pre>
</li><br />
<li>Numpyを使って書き出す（npy）
<pre>np.save('ファイルへのパス', d)</pre>
＊dは配列ndarray
</li><br />
<li>Numpyを使って書き出す（npz）
<pre>np.savez('ファイルへのパス', d1, d2)</pre>
＊d1, d2は配列ndarray
</li><br />
<li>Numpyを使って書き出す（npz、キーワードあり）
<pre>np.savez('ファイルへのパス', data=d, lons=lons, lats=lats)</pre>
＊d、lons、latsは配列ndarray
</li><br />
<li>Numpyを使って書き出す（npz、キーワードあり、圧縮）
<pre>np.savez_compressed('ファイルへのパス', data=d, lons=lons, lats=lats)</pre>
</li><br />
<li>Numpyを使って読み込む（npz、キーワードあり）
<pre>d = np.load('ファイルへのパス')
lons = d['lons']
lats = d['lats']
data = d['data']
</pre>
＊lons、lats、dataに保存した配列が入る
</li><br />
</ul>
</div>


<!--  NetCDFファイル -->
<h3><div class="headline1" id="nc_1">NetCDFファイル</div></h3>
<h4><div class="headline2" id="nc_1_1">NetCDFファイルの形式</div></h4>
<div class="text1">
NetCDFファイルには、データと一緒に格子点の情報やデータの説明も一緒に格納されている。データの説明も格納できるため、データを作成したモデルの名前や作成者、変数の導出方法、参照元の文献やURL などを記述しておけば、利用者がデータの中身を理解しやすい。また、格納されたデータを機種に依存することなく取り出せるため、データの配布に適している。
</div>

<h4><div class="headline2" id="nc_1_2">NetCDFのモジュール</div></h4>
<div class="text1">
モジュールをインポートする
<pre>import netCDF4</pre><br />
インポートでエラーが出る場合
<ul class="list1">
<li>MacPortsでpython3.11のnetcdfライブラリをインストール
<pre>
% sudo port install py311-netcdf4
</pre>
＊pythonのバージョンが異なる場合には、py311の部分を対応するものに変える<br />
＊HomebrewやAnacondaを使っている場合には、競合を避けるためMacPortsは使わない方が良い
</li>
</ul>
</div>

<h4><div class="headline2" id="nc_1_3">NetCDFファイルの読み込み</div></h4>
<div class="text1">
NetCDFファイルに含まれている変数名などを確認する
<pre>% ncdump -h ファイル名</pre>
ファイルを開き、指定した変数名のデータを取り出す
<pre>
nc = netCDF4.Dataset('ファイル名', 'r')
var = nc.variables['変数名'][:]
</pre>
<ul class="list1">
<li>例：SLPデータの読み込み（変数名slpの場合）
<pre>
nc = netCDF4.Dataset('ファイル名', 'r')
var = nc.variables['slp'][:]
</pre></li>
<li>例：軸情報の読み込み
<pre>
lon = nc.variables["lon"][:] # 経度
lat = nc.variables["lat"][:] # 緯度
time = nc.variables["time"][:] # 時刻
</pre>
</li>
</ul>
</div>

<h4><div class="headline2" id="nc_1_4">NetCDFファイル情報の取得</div></h4>
<div class="text1">
<pre>
nc = netCDF4.Dataset('ファイル名', 'r')
idim = len(nc.dimensions['lon']) # 経度方向のデータ数
jdim = len(nc.dimensions['lat']) # 緯度方向のデータ数
ndim = len(nc.dimensions['time']) # 時間方向のデータ数
add_offset = nc.variables['変数名'].add_offset # データのオフセット
scale_factor = nc.variables['変数名'].scale_factor # データのスケールファクター
</pre>
</div>

<h4><div class="headline2" id="nc_1_5">データにスケールファクターとオフセットがある場合</div></h4>
<div class="text1">
<pre>
nc = netCDF4.Dataset('ファイル名', 'r')
var_i = nc.variables['変数名'][:]
add_offset = nc.variables['変数名'].add_offset
scale_factor = nc.variables['変数名'].scale_factor
var = var_i * scale_factor + add_offset
</pre>
</div>

<h4><div class="headline2" id="nc_1_6">変数がグループ化されている場合</div></h4>
<div class="text1">
グループ化されている場合、
<pre>% ncdump -h ファイル名</pre>
でvariablesの上位にgroupが表示される。その場合、groupの下位に表示される変数名（ここでは変数名1、変数名2があるものとする）を使い、以下のように取り出す
<pre>
nc = netCDF4.Dataset('ファイル名', 'r')
grp = nc.groups['グループ名']
var1 = grp.variables['変数名1'][:]
var2 = grp.variables['変数名2'][:]
</pre>
</div>


 <!--  GRIB2ファイル -->
<h3><div class="headline1" id="grib2_1">GRIB2ファイル</div></h3>
<h4><div class="headline2" id="grib2_1_1">GRIB2ファイルの形式</div></h4>
<div class="text1">
WMOが定めたバイナリデータの交換形式のうち、2001年に制定された第2版を指す。後述の<a href="#grib1_1">GRIB1形式</a>とは互換性がない。格納されたデータを機種に依存することなく取り出すことができ、データと一緒に格子点の情報や変数の簡単な説明等も格納できる。詳細については<a href="https://qiita.com/e_toyoda/items/ce7497e1a633b16f1ff1">Qiitaの記事</a>に詳しい。
</div>

<h4><div class="headline2" id="grib2_1_2">GRIB2ファイルの読み込み</div></h4>
<div class="text1">
GRIB2ファイルの読み込みを行うには、まずGRIB2からNetCDFへ変換し、NetCDFとして読み込む方法が良い。変換にはwgrib2を用いる。MacPortsであれば、
<pre>
% sudo port install wgrib2
</pre>
で導入できる。wgrib2を用いて次のように変換する。
<pre>% wgrib2 入力ファイル名 -netcdf 出力ファイル名</pre>
変換後のファイルは、<a href="#nc_1">NetCDF</a>に記述した方法で読み込み可能<br />
＊wgrib2のバージョン3.1.2ではJPEG2000のエラーが発生するデータが存在する。バージョン3.1.3では解消された。
</div>

<h4><div class="headline2" id="grib2_1_3">pygribを使ったGRIB2ファイルの読み込み</div></h4>
<div class="text1">
pygribモジュールを用いると、直接GRIB2ファイルを読み込むことができた。
<pre>
% sudo port install py310-pygrib
</pre>
で導入できる（python3.10の場合。異なるバージョンではpy310の部分を変える）。pygribでは次のようにデータを取り出す。
<pre>
import pygrib
grbs = pygrib.open("ファイル名") # GRIB2ファイルを開く
grb1 = grbs.select(forecastTime=1)[0] # 1時間後の0番目の変数
grbt = grbs.select(name="Temperature") # 気温の変数を選択
</pre>
ファイルの読み込みに時間がかかるため、読み込み処理が多い場合には<a href="#grib2_1_2">GRIB2ファイルの読み込み</a>に記述した方法に切り替えた方が良い。<br />
＊MacPortsでは、python3.11以降のpygribが提供されていない。
</div>

<h4><div class="headline2" id="grib2_1_4">wgrib2による単純バイナリファイルへの変換</div></h4>
<div class="text1">
<a href="https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/">wgrib2コマンド</a>を使うと、単純バイナリファイルに変換可能。変換したファイルの読み込み方法は<a href="#bin_1_3">バイナリファイルの読み込み</a>参照。北極が先、下層が先に入ったビックエンディアンの単純バイナリファイルに変換する場合
<pre>
% wgrib2 -v 入力ファイル.grb | grep "変数名" | grep "時刻" | sort -nr -k5 -t':' \
  | wgrib2 入力ファイル.grb -i -no_header -order we:ns -ieee -o 出力ファイル.bin
</pre>
＊-no_headerはヘッダ無し、-ieeeはビックエンディアン<br />
＊-order we:nsで、西から東、北から南の順に並べ替えて出力<br />
＊下層が先になるように、sort -nr -k5 -t':'で並べ替えを行っている<br />
＊最初のwgrib2は、ファイルの中に含まれる変数をリスト化するためのもので、2回目のwgrib2は、リストを読み込んで入力ファイルからリストに対応するデータをファイルに書き出すためのもの。grepやsortでリストのうち必要な変数の取り出しや並べ替えを行う。<br />
＊追加書き込みを行う際には、wgrib2 入力ファイル.grb -i -no_header -append -order we:ns -ieee -o 出力ファイル.bin<br />
</div>


 <!--  GRIB1ファイル -->
<h3><div class="headline1" id="grib1_1">GRIB1ファイル</div></h3>
<h4><div class="headline2" id="grib1_1_1">GRIB1ファイルの形式</div></h4>
<div class="text1">
WMOが定めたバイナリデータの交換形式のうち、1989年に制定された第1版を指す。前述の<a href="#grib2_1">GRIB2形式</a>とは互換性がない。格納されたデータを機種に依存することなく取り出せ、データと一緒に格子点の情報や変数の簡単な説明等も格納できる。
</div>

<h4><div class="headline2" id="grib1_1_2">GRIB1ファイルの読み込み</div></h4>
<div class="text1">
GRIB1形式は、pythonで直接読むことはできないが、GrADSに付属しているwgribコマンドを使うことで、単純バイナリファイルに変換可能。変換したファイルの読み込み方法は<a href="#bin_1_3">バイナリファイルの読み込み</a>参照。JRA-55客観解析データの気圧面データを使い、下層が先に入ったビックエンディアンの単純バイナリファイルに変換する場合
<pre>
% wgrib -v 入力ファイル.grb | grep ":GRIBIDを記述," | sort -nr -k5 -t':' \
  | wgrib -i -nh -ieee 入力ファイル.grb -o 出力ファイル.bin
</pre>
＊-nhはヘッダ無し、-ieeeはビックエンディアン<br />
＊下層が先になるように、sort -nr -k5 -t':'で並べ替えを行っている<br />
＊最初のwgribは、ファイルの中に含まれる変数をリスト化するためのもので、2回目のwgribは、リストを読み込んで入力ファイルからリストに対応するデータをファイルに書き出すためのもの。grepやsortでリストのうち必要な変数の取り出しや並べ替えを行う。<br />
＊追加書き込みを行う際には、wgrib -i -nh -ieee -append 入力ファイル.grb 出力ファイル.bin<br />
</div>


 <!--  HDF5ファイル -->
<h3><div class="headline1" id="hdf5_1">HDF5ファイル</div></h3>
<h4><div class="headline2" id="hdf5_1_1">HDF5ファイルの形式</div></h4>
<div class="text1">
HDF形式は、米国立スーパーコンピュータ応用研究所（National Center for Supercomputing Applications：NCSA）で開発され、大量のデータを格納し構造化するために設計されている。データと一緒に格子点の情報や変数の説明なども格納することができ、格納されたデータを機種に依存することなく取り出せる。HDF形式には、古いHDF4形式と新しいHDF5形式があり、両者に互換性はない。HDF5はファイル構造が単純化されており、ディレクトリに相当するグループとファイルに相当するデータセットの２種類で階層構造を持って保存することができる。
</div>

<h4><div class="headline2" id="hdf5_1_2">HDF5ファイルの読み込み</div></h4>
<div class="text1">
Pythonでは、Pandasやh5pyでHDF5ファイルを読むことができる。Pandasで読み込めない形式の場合にはh5pyを使う。
<ul class="list1">
<li>例：Pandasを使った方法
<pre>
import pandas as pd
df = pd.read_hdf("ファイル名")
</pre></li>
<li>例：h5pyを使った方法<br />
Python3.11の場合、MacPortsを使い次のようにインストール（バージョンが異なる場合はpy311の部分を変える）
<pre>% sudo port install py311-h5py</pre>
２次元データをdに格納する場合
<pre>
import h5py
hdf = h5py.File("ファイル名", "r") # HDF5ファイルを開く
d = hdf['データセットの名前'][:, :] # データセットの名前に対応するデータを取得
</pre>
＊以前はhdf['データセットの名前'].valueを使うことができたが、現在のバージョンではエラーが出る。<br />
＊データセットの名前を表示したい場合には、print(hdf.keys())</li>
</ul>
</div>


 <!--  GTOOL3ファイル -->
<h3><div class="headline1" id="gtool3_1">GTOOL3ファイル</div></h3>
<h4><div class="headline2" id="gtool3_1_1">GTOOL3ファイルの形式</div></h4>
<div class="text1">
GTOOL3形式は、気候モデルMIROCの出力に用いられているバイナリ形式で、ヘッダ部とデータ部のセットで構成され改行コードで区切られている。ヘッダ部にはデータ部の格納形式（例えば、1レコードが4バイトか8バイトか）やサイズ、欠損値、日時などが16 文字&#215;64欄の文字データとして格納されている。また、データの経度、緯度、高度方向の格子点数や、格子点値が記述された格子情報ファイル名なども格納され、データの名前、作成 、作成日時なども記述することができる。データ部は単純バイナリで、ビックエンディアン、リトルエンディアンどちらも許容されており、機種依存性がある。
<ul class="list1">
<li>GTOOL3ファイルの形式
<pre>
t=0：| ヘッダ部（16 文字&#215;64欄）| 改行コード
t=0：| データ部 | 改行コード
t=1：| ヘッダ部（16 文字&#215;64欄）| 改行コード
t=1：| データ部 | 改行コード
...
</pre>
| |で囲まれた部分がヘッダ部やデータ部を表す。
</li>
</ul>
</div>

<h4><div class="headline2" id="gtool3_1_2">GTOOL3ファイルの読み込み</div></h4>
<div class="text1">
GTOOL3の読み込みには、<a href="https://github.com/hyungjun/gtool3/" target="_blank">gtool3更新版</a>を用いることができる。
<pre>
from gtool3 import gtopen
gt = gtopen("ファイル名") # GTOOL3ファイルを開く
d = gt['変数名'][:, :, :, :] # 変数名に対応するデータ取得（次元はデータに合わせる）
</pre>
＊時刻、高度、緯度、経度が入ったデータの場合<br />
＊変数名や次元はgt.varsで表示できる。<br />
＊気候モデルのMIROCの出力を用いた処理方法は、<a href="https://isotope.iis.u-tokyo.ac.jp/~kanon/src/gtool4python.html">PythonでGTOOL3ファイルを処理する</a>に詳しい。
</div>



<!--  画像ファイル -->
<h3><div class="headline1" id="img_1">画像ファイル</div></h3>
<h4><div class="headline2" id="img_1_1">画像ファイルの読み込み（Pillow）</div></h4>
<div class="text1">
ここでは、様々な画像フォーマットに対応しているPillowを利用した読み込み方法を紹介する。Pillowでは、PNG、BMP、GIF、JPEG、TIFF、EPSなど、主要な形式の読み書きに対応している。読み込む場合には、
<pre>from PIL import Image
im = Image.open("画像ファイルのパス")
</pre>
Numpyで扱う場合には、次のようにndarrayに変換する
<pre>im = np.asarray(im)</pre>
urllibを利用して、web上の画像を読み込むことも可能
<pre>from PIL import Image
import urllib.request
im = Image.open(urllib.request.urlopen("URLを指定"))
</pre>
</div>

<h4><div class="headline2" id="img_1_2">画像ファイルの書き出し（Pillow）</div></h4>
<div class="text1">
Pillowで書き出す場合には、
<pre>im.save("画像ファイル名")</pre>
書き出す画像の質を指定する場合（jpg）、
<pre>im.save("画像ファイル名.jpg", quality=95)</pre>
</div>

<h4><div class="headline2" id="img_1_3">読み込んだ画像の処理（Pillow）</div></h4>
<div class="text1">
Pillowの機能としてグレースケール変換、切り出し、サイズの変更などが可能。
<ul class="list1">
<li>グレースケール変換
<pre>from PIL import Image
im = Image.open("画像ファイルのパス")
im_gray = im.convert('L') # グレースケールに変換
</pre>
</li>
<li>切り出し
<pre>im = im.crop((0, 50, 600, 300))</pre>
座標は(left, upper, right, lower)で指定する<br />
tupleで与えるので、括弧が2重になっている
</li><br />
<li>サイズの変更
<pre>im = im.resize((128, 128))</pre>
128x128ピクセルに変換する
</li><br />
<li>サイズの変更（手法の指定）
<pre>im = im.resize((128, 128), Image.LANCZOS)</pre>
LANCZOSフィルターを用いる<br />
デフォルトはNEARESTフィルター<br />
NEAREST、BOX、BILINEAR、HAMMING、BICUBIC、LANCZOSが指定可能（後のものほど高品質で処理時間かかる）
</li><br />
<li>画像の回転
<pre>im = im.rotate(90))</pre>
90度回転する
</li><br />
<li>カラー画像のRGB成分を取り出す
<pre>r, g, b = im.split()</pre>
</li>
<li>取り出したRGB成分をBRGに入れ替える
<pre>im = Image.merge("RGB", (b, r, g))</pre>
</li>
</ul>
</div>


<small><a href="#top">[top]</a></small> <br />
<hr width="105%" />
</article>
</body>
<footer>
<p>最終更新日：2025/05/22</p>
<p>Copyright (C) 2018-2025, Yousuke Yamashita, CC BY 4.0</p>
</footer>
</html>
